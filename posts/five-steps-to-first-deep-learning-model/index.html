<!DOCTYPE html>
<html prefix="
        og: http://ogp.me/ns# article: http://ogp.me/ns/article#
    " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>In 5 easy steps to your first deep learning model | Tobias Budig</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://tobias-budig.com/posts/five-steps-to-first-deep-learning-model/">
<!--[if lt IE 9]><script src="../../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><meta name="author" content="Tobias Budig">
<meta property="og:site_name" content="Tobias Budig">
<meta property="og:title" content="In 5 easy steps to your first deep learning model">
<meta property="og:url" content="https://tobias-budig.com/posts/five-steps-to-first-deep-learning-model/">
<meta property="og:description" content="With fast.ai everyone can train their own deep learning model. Only 5 steps are necessary.

Find a dataset
Make data available in code
Prepare data
Training of the model
Use it

We want to train a neu">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2020-11-16T10:30:13+01:00">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Learning">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Tech">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700%7CPlayfair+Display:400,700" rel="stylesheet">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
<link rel="stylesheet" href="../../assets/css/style.css">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-RXBBX0KET2"></script><script>
  var dnt = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
  if (dnt != "1" && dnt != "yes") {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-RXBBX0KET2');
  } else {
    console.debug("Respecting Do-Not-Track, not loading analytics. See https://www.paulfurley.com/google-analytics-dnt/");
  }
</script>
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="container">
             <header id="header"><p id="brand" class="display-1">
        <a href="https://tobias-budig.com/" title="Tobias Budig" rel="home">

            <span id="blog-title">Tobias Budig</span>
        </a>
    </p>

            <nav><ul class="nav justify-content-center">
<li class="nav-link">
                <a href="../../founder/">Founder</a>
            </li>
            <li class="nav-link">
                <a href="../../techie/">Techie</a>
            </li>
            <li class="nav-link">
                <a href="../../blog/">Blog</a>
            </li>
        </ul></nav></header><main id="content" class="page"><hr style="margin-bottom: 50px">
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">In 5 easy steps to your first deep learning model</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Tobias Budig
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2020-11-16T10:30:13+01:00" itemprop="datePublished" title="2020-11-16">2020-11-16</time></a>
            </p>
                    <p class="sourceline"><a href="index.md" class="sourcelink">Source</a></p>

        </div>
        
    </header><div class="e-content entry-content" itemprop="articleBody text">
        <div>
<p>With fast.ai everyone can train their own deep learning model. Only 5 steps are necessary.</p>
<ol>
<li>Find a dataset</li>
<li>Make data available in code</li>
<li>Prepare data</li>
<li>Training of the model</li>
<li>Use it</li>
</ol>
<p>We want to train a neural network to help doctors detect pneumonia from x-rays.  We will go through the process step by step. The learning success is best if you type the lines yourself.
<!-- TEASER_END --></p>
<h4>1. Find a dataset</h4>
<p>Without data there is no machine learning - that is clear. Since we want to classify image data in this example, there are several ways to get a data set.
<!-- status: draft-->
- You already have data. In the example if you are a radiologists.
- Collect images from the internet ("scrapping")
- Use public data sets</p>
<p>In this case, we use the last approach because it is easy and available to everyone. Known data sets are MINST (handwritten numbers), .... Large picture DB or ...
A place to found a range of datasets is <a href="https://www.kaggle.com">Kaggle</a>. On this platform, competitions on machine learning topics take place. The data sets are also public, because everybody can participate in the competitions. There we find our <a href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia">x-ray images</a>, which are already "labeled". This means that this images are classified as normal or sick. After downloading the data we are ready for the next step.</p>
<h4>2. Make data available in code</h4>
<p>Python is used as programming language. As intuitive programming environment we use <a href="https://jupyter.org/">Jupiter notebook</a>. You can use <a href="https://colab.research.google.com/">Google Colab</a> or <a href="https://www.paperspace.com/core">Paperspace</a> for free to start. I can recommend the last one. Here we use <a href="https://docs.fast.ai">fast.ai</a> library, because there are many functions already available to run own models quickly. YOu can run all code snippets in a new cell.</p>
<pre class="code literal-block"><span class="kn">from</span> <span class="nn">fastai</span> <span class="kn">import</span> <span class="o">*</span>
</pre>

<p>After importing the library, we check whether the directory with the training data is located in the right place. If not already done, the downloaded folder has to be unzipped and moved into the folder with the Jupiter notebook.</p>
<pre class="code literal-block"><span></span><code><span class="sx">!ls</span>
</code></pre>


<p>We can now see that the folder is in the right place. After that we set the path to the images and check a second time if everything worked out fine.</p>
<pre class="code literal-block"><span></span><code><span class="n">Path</span><span class="o">.</span><span class="n">BASE_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">'./chest_xray_data/'</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="o">.</span><span class="n">BASE_PATH</span>
<span class="n">Path</span><span class="o">.</span><span class="n">BASE_PATH</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</code></pre>


<h4>3. Prepare data</h4>
<p>Because we process images. Let's first check if there are files in the image folder that are not images and could later lead to errors.</p>
<pre class="code literal-block"><span></span><code><span class="n">fns</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">fns</span>
</code></pre>


<p>Next, we crate a DataBlock which contains information about our data and for the train process later.</p>
<pre class="code literal-block"><span></span><code><span class="n">xrays</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span>
    <span class="c1"># indicates that our input data are images and our predictions are categories</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">ImageBlock</span><span class="p">,</span> <span class="n">CategoryBlock</span><span class="p">),</span>
    <span class="c1"># specifies the input data as images from the provided path</span>
    <span class="n">get_items</span><span class="o">=</span><span class="n">get_image_files</span><span class="p">,</span>
    <span class="c1"># splitting the dataset in train and validationset randomy with seed 42</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">RandomSplitter</span><span class="p">(</span><span class="n">valid_pct</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="c1"># sets the label as the name of the partent directory</span>
    <span class="n">get_y</span><span class="o">=</span><span class="n">parent_label</span><span class="p">,</span>
    <span class="c1"># resizes images to 128px x 128px</span>
    <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
<span class="p">)</span>
</code></pre>


<h4>4. Training</h4>
<p>Surprisingly, most of the work is inside the preparation. After the structure of the network has been defined (Datablock) and linked to the training data (Dataloader), we are ready.</p>
<pre class="code literal-block"><span></span><code><span class="n">dls</span> <span class="o">=</span> <span class="n">xrays</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre>


<p>Now, we can watch in the preperad data by looking at the first four pictures from the first batch.</p>
<pre class="code literal-block"><span></span><code><span class="n">dls</span><span class="o">.</span><span class="n">valid</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre>


<p>Output:
<img alt="Result show batch" src="https://tobias-budig.com/img/result-show-batch.png" title="Result show batch" width="90%"></p>
<p>Next, we train the convolutional neural network (CNN), a special type of neural network that is particularly suitable for image data.  In addition, we use a pre-trained model <a href="https://www.kaggle.com/pytorch/resnet18">("Resnet18")</a> to get better resultes quickly and set the target metric to the error rate in the validation set.</p>
<pre class="code literal-block"><span></span><code><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">error_rate</span><span class="p">)</span>
</code></pre>


<p>The learning process takes longer or shorter depending on the computer. After the first run, however, the model already reaches over 90% accuracy. The error rate can be further reduced by more training</p>
<pre class="code literal-block"><span></span><code><span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre>


<p>Output
<img alt="Result train process" src="https://tobias-budig.com/img/result-train-nn.png" title="Result train process" width="90%"></p>
<p>In this example, an accuracy of over 97% is achieved.</p>
<p>A more precise evaluation provides 13 false negative and 20 false positive of a total of 1171 images</p>
<pre class="code literal-block"><span></span><code><span class="n">interp</span> <span class="o">=</span> <span class="n">ClassificationInterpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
<span class="n">interp</span><span class="o">.</span><span class="n">plot_confusion_matrix</span><span class="p">()</span>
</code></pre>


<p>Output:
<img alt="Confusion matrix to evaluate performance" src="https://tobias-budig.com/img/result-matrix.png" title="Confusion matrix to evaluate performance" width="90%"></p>
<p>The top 5 images where the model is most uncertain can be viewed above this command and any incorrectly forked data can be identified.</p>
<pre class="code literal-block"><span></span><code><span class="n">interp</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre>


<p>Finally, we can save the model for later use without training again.</p>
<pre class="code literal-block"><span></span><code><span class="n">learn</span><span class="o">.</span><span class="n">export</span><span class="p">()</span>
</code></pre>


<h4>5. Apply</h4>
<p>We can import the saved model </p>
<pre class="code literal-block"><span></span><code><span class="n">learn_inf</span> <span class="o">=</span> <span class="n">load_learner</span><span class="p">(</span><span class="s2">"./export.pkl"</span><span class="p">)</span>
</code></pre>


<p>and use the neural network to predict a new image.</p>
<pre class="code literal-block"><span></span><code><span class="n">pred</span><span class="p">,</span> <span class="n">pred_idx</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">learn_inf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Predictions: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">; Probability: </span><span class="si">{</span><span class="n">probs</span><span class="p">[</span><span class="n">pred_idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.04f</span><span class="si">}</span><span class="s2">"</span>
<span class="n">result</span>
</code></pre>


<h4>Bonus</h4>
<p>This snippet creates a widget to upload a imgage which is than classified.</p>
<pre class="code literal-block"><span></span><code><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">VBox</span>
<span class="n">btn_upload</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FileUpload</span><span class="p">()</span>
<span class="n">out_pl</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
<span class="n">lbl_pred</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Label</span><span class="p">()</span>
<span class="n">btn_run</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Classify"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_click_classify</span><span class="p">(</span><span class="n">change</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">PILImage</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">btn_upload</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">out_pl</span><span class="o">.</span><span class="n">clear_output</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">out_pl</span><span class="p">:</span> <span class="n">display</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">to_thumb</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>

    <span class="c1">#get predictions</span>
    <span class="n">pred</span><span class="p">,</span> <span class="n">pred_idx</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">learn_inf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>


    <span class="n">lbl_pred</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"Predictions: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">; Probability: </span><span class="si">{</span><span class="n">probs</span><span class="p">[</span><span class="n">pred_idx</span><span class="p">]</span><span class="si">:</span><span class="s2">.04f</span><span class="si">}</span><span class="s2">"</span>
    <span class="n">lbl_pred</span>

<span class="n">btn_run</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_click_classify</span><span class="p">)</span>
<span class="n">VBox</span><span class="p">([</span><span class="n">widgets</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="s2">"Select Image"</span><span class="p">),</span> <span class="n">btn_upload</span><span class="p">,</span> <span class="n">btn_run</span><span class="p">,</span> <span class="n">out_pl</span><span class="p">,</span> <span class="n">lbl_pred</span><span class="p">])</span>
<span class="n">result</span>
</code></pre>


<p>Now, we are done and have simple classifier to support dotors!</p>
<p>See the repo here on <a href="https://github.com/tobiasbudig/x-ray-chest-analysis">GitHub</a>.</p>
</div>
    </div>

    <hr class="mt-5 mb-5">
<aside class="postpromonav"><nav><p class="mb-0">Tags:</p>
                    <ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/ai/" rel="tag">AI</a></li>
            <li><a class="tag p-category" href="../../categories/learning/" rel="tag">Learning</a></li>
            <li><a class="tag p-category" href="../../categories/python/" rel="tag">Python</a></li>
            <li><a class="tag p-category" href="../../categories/tech/" rel="tag">Tech</a></li>
        </ul>
<p class="mb-0">Posts:</p>
            
        </nav></aside></article><hr style="margin-top: 50px"></main><nav><ul class="nav justify-content-center">
<li class="nav-link">
                 <a href="../../archive.html">Archive</a>
             </li>
             <li class="nav-link">
                 <a href="../../categories/">Categories</a>
             </li>
             <li class="nav-link">
                 <a href="../../rss.xml">RSS feed</a>
             </li>
         </ul></nav><footer><p>I'm Tobias Budig – Techie, Founder, and Learning-Enthusiast living in Karlsruhe, Germany. Let's get in touch.</p>
    <p class="lead socials">
            <a href="https://github.com/tobiasbudig" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.instagram.com/tobias.budig" target="_blank"><i class="fab fa-instagram"></i></a> 
            <a href="https://www.linkedin.com/in/tobias-budig" target="_blank"><i class="fab fa-linkedin"></i></a>
    </p>
    <p>
        This site uses cookies and external services to improve your experience.<br>
        At least if you don't refuse by sending <a href="http://randomwalker.info/donottrack-archive/" target="_blank">Do Not Track</a>.
    </p>
    <p>© Copyright 2020 by Tobias Budig. <a href="https://www.tobias-budig.com/impressum" target="_blank">Legal/Imprint</a>.</p>
</footer>
</div>
                <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
